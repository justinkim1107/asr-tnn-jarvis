# Automatic Speech Recognition and Response using Transformer Neural Networks

![alt text](https://github.com/justinkim1107/asr-tnn-jarvis/blob/main/images/jarvis.jpeg?raw=true)

## Project Description 

I will focus on training neural networks (NNs) for the task of translating and interpreting speech. The model will process the speech input and translate the data into a discrete output using feature-extraction. It will then interpret and classify the output before responding appropriately. 

The recent development of the Transformer Neural Network model has yielded significant improvement in speech recognition in comparison to Convolutional (CNNs) and Recurrent Nuerual Network (RNNs) models. Further research of combinations of CNNs and RNNs with Transformers have found significant results which could prove useful to the model. The trained NN will be "deployed" as an application by testing the model with new, unfamiliar speech inputs. The model with then use training data to correctly interpret the inputs and respond empathetically (i.e. sarcastically or sympathetically).

The initial focus of the project will be to understand and train a Transformer Neural Network model. The longer-term goal is to use a NN to enable the model to both respond to and carry out user requests. In order to refine interpretation in complex conversational environments, further research in analyzing the tone and pitch of speech would improve upon the model's ability to interact. The results from this work could potentially decrease the gap between human and machine conversations. 


## Project Goals

1. Gather/Generate sufficient training data
2. Train a NN to translate and interpret data
3. Classification
4. Train model to respond appropriately

## Works Cited 

Papastratis, Ilias. “Speech Recognition: A Review of the Different Deep Learning Approaches.” AI Summer, Sergios Karagiannakos, 14 July 2021, https://theaisummer.com/speech-recognition/#transformers. 
